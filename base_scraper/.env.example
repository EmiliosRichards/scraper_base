# Core Scraping Parameters
SCRAPER_USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
SCRAPER_PAGE_TIMEOUT_MS=30000
SCRAPER_NAVIGATION_TIMEOUT_MS=60000
SCRAPER_MAX_RETRIES=2
SCRAPER_RETRY_DELAY_SECONDS=5
MAX_DEPTH_INTERNAL_LINKS=1
SCRAPER_NETWORKIDLE_TIMEOUT_MS=3000

# Link Prioritization and Filtering
TARGET_LINK_KEYWORDS=about,company,services,products,solutions,team,mission,contact,imprint,datenschutz,impressum,ueber-uns,ueber_uns,kontakt
SCRAPER_CRITICAL_PRIORITY_KEYWORDS=impressum,imprint,about-us,about_us,ueber-uns,ueber_uns
SCRAPER_HIGH_PRIORITY_KEYWORDS=services,products,solutions,leistungen,produkte
SCRAPER_EXCLUDE_LINK_PATH_PATTERNS=/media/,/blog/,/wp-content/,/video/,/news/

# Scraping Limits and Scoring
SCRAPER_MAX_PAGES_PER_DOMAIN=20
SCRAPER_MIN_SCORE_TO_QUEUE=40
SCRAPER_SCORE_THRESHOLD_FOR_LIMIT_BYPASS=80
SCRAPER_MAX_HIGH_PRIORITY_PAGES_AFTER_LIMIT=5
SCRAPER_MAX_KEYWORD_PATH_SEGMENTS=3

# Content and Summary
SCRAPER_PAGES_FOR_SUMMARY_COUNT=3
LLM_MAX_INPUT_CHARS_FOR_SUMMARY=40000

# Output and Filenames
OUTPUT_BASE_DIR=output_data
FILENAME_COMPANY_NAME_MAX_LEN=25
FILENAME_URL_DOMAIN_MAX_LEN=8
FILENAME_URL_HASH_MAX_LEN=8

# Robots.txt Handling
RESPECT_ROBOTS_TXT=True
ROBOTS_TXT_USER_AGENT=*

# URL Probing and Fallbacks
URL_PROBING_TLDS=de,com,at,ch
ENABLE_DNS_ERROR_FALLBACKS=True

# Page Type Classification
PAGE_TYPE_KEYWORDS_ABOUT=about,about-us,company,profile,mission,vision,team,ueber-uns,ueber_uns,unternehmen
PAGE_TYPE_KEYWORDS_PRODUCT_SERVICE=products,services,solutions,offerings,platform,features,produkte,leistungen,loesungen

# --- Caching Settings ---
# Enable or disable the file-based cache for scraping results.
CACHING_ENABLED=True
# The directory where cache files will be stored.
CACHE_DIR=cache
# --- Advanced Scraper Features ---

# --- Proxy Management ---
# Enable or disable the use of proxies for IP rotation.
PROXY_ENABLED=False
# Provide a comma-separated list of your proxy URLs.
# Example: PROXY_LIST="http://user:pass@proxy1.com:8080,http://user:pass@proxy2.com:8080"
PROXY_LIST=
# Choose the proxy rotation strategy: 'random', 'sequential', or 'rotate_on_failure'.
PROXY_ROTATION_STRATEGY=random
# Enable or disable automatic health checks for proxies.
PROXY_HEALTH_CHECK_ENABLED=True
# Set the cooldown period in seconds for a failing proxy before it's retried.
PROXY_COOLDOWN_SECONDS=300

# --- Interaction Handling ---
# Enable or disable the automatic handling of modals (cookie banners, pop-ups).
INTERACTION_HANDLER_ENABLED=True
# Comma-separated list of CSS selectors for elements to click.
INTERACTION_SELECTORS="button[id*='accept'],button[id*='agree'],button[id*='consent'],button[id*='cookie']"
# Comma-separated list of text queries to find on clickable elements.
INTERACTION_TEXT_QUERIES="Accept all,Agree,Consent,I agree"
# Timeout in seconds for the interaction handler loop.
INTERACTION_HANDLER_TIMEOUT_SECONDS=5

# --- CAPTCHA Solving ---
# Enable or disable third-party CAPTCHA solving.
CAPTCHA_SOLVER_ENABLED=False
# Specify the CAPTCHA solving service provider (e.g., '2captcha').
CAPTCHA_PROVIDER=2captcha
# Your API key for the chosen CAPTCHA solving service.
CAPTCHA_API_KEY=